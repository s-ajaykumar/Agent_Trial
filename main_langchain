from langchain.agents import create_agent
from langchain.chat_models import init_chat_model
from dotenv import load_dotenv
from langchain.tools import tool
from langgraph.checkpoint.postgres.aio import AsyncPostgresSaver
from config import DB_URI
import asyncio 

load_dotenv()


# Prompt
system_prompt = """You are an expert weather forecaster.

You have access to two tools:

- get_weather: use this to get the weather for a specific location

If a user asks you for the weather of a city use the get_weather tool to find the weather and show the tool response to the user."""


# Tools
@tool
def get_weather(city: str) -> str:
    """Get weather for a given city"""
    return f"It's sunny in {city}"


# Agent
model = init_chat_model(
    'google_genai:gemini-2.5-flash-lite',
    temperature = 0.01,
    max_tokens = 1000
    )


# Config
config = {
    'configurable' : {
        'thread_id' : 1
        }
    }


# Inference
async def main():
    # Langgraph
    print('Creating checkpointer...')
    async with AsyncPostgresSaver.from_conn_string(DB_URI) as checkpointer:
        await checkpointer.setup()    # Create tables
        agent = create_agent(
            model = model,
            tools = [get_weather],
            system_prompt = system_prompt,
            checkpointer = checkpointer
        )
        res = await agent.ainvoke(
                {'messages' : [{'role' : 'user', 'content' : 'whats the weather in Madurai'}]},
                config = config
            )
        print(res['messages'])


if __name__ == '__main__':
    asyncio.run(main())
    